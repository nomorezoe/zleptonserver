{
  "1": {
    "inputs": {
      "image": "save (20).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "realismEngineSDXL_v20VAE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "22": {
    "inputs": {
      "control_net_name": "OpenPoseXL2.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "26": {
    "inputs": {
      "images": [
        "28",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "28": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 512,
      "bbox_detector": "yolox_l.onnx",
      "pose_estimator": "dw-ll_ucoco_384.onnx",
      "image": [
        "1",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "29": {
    "inputs": {
      "control_net_name": "control-lora-depth-rank128.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "31": {
    "inputs": {
      "images": [
        "33",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "33": {
    "inputs": {
      "a": 6.283185307179586,
      "bg_threshold": 0.1,
      "resolution": 512,
      "image": [
        "1",
        0
      ]
    },
    "class_type": "MiDaS-DepthMapPreprocessor",
    "_meta": {
      "title": "MiDaS Depth Map"
    }
  },
  "51": {
    "inputs": {
      "width": [
        "183",
        0
      ],
      "height": [
        "183",
        1
      ],
      "batch_size": 4
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "52": {
    "inputs": {
      "switch_1": "Off",
      "lora_name_1": "real-humans-PublicPromptsXL.safetensors",
      "model_weight_1": 0.9500000000000001,
      "clip_weight_1": 1,
      "switch_2": "On",
      "lora_name_2": "None",
      "model_weight_2": 1,
      "clip_weight_2": 1,
      "switch_3": "On",
      "lora_name_3": "None",
      "model_weight_3": 1,
      "clip_weight_3": 1,
      "lora_stack": [
        "54",
        0
      ]
    },
    "class_type": "CR LoRA Stack",
    "_meta": {
      "title": "[Optional] CR LoRA Stack"
    }
  },
  "53": {
    "inputs": {
      "model": [
        "4",
        0
      ],
      "clip": [
        "149",
        0
      ],
      "lora_stack": [
        "52",
        0
      ]
    },
    "class_type": "CR Apply LoRA Stack",
    "_meta": {
      "title": "ðŸ’Š CR Apply LoRA Stack"
    }
  },
  "54": {
    "inputs": {
      "switch_1": "On",
      "lora_name_1": "Cinematic Hollywood Film_sdxl.safetensors",
      "model_weight_1": 1.5,
      "clip_weight_1": 1,
      "switch_2": "On",
      "lora_name_2": "SDXL1.0_Essenz-series-by-AI_Characters_Style_BetterPhotography-v1.2-'Skynet'.safetensors",
      "model_weight_2": 1.5,
      "clip_weight_2": 1,
      "switch_3": "Off",
      "lora_name_3": "None",
      "model_weight_3": 1,
      "clip_weight_3": 1
    },
    "class_type": "CR LoRA Stack",
    "_meta": {
      "title": "[Optional] CR LoRA Stack"
    }
  },
  "55": {
    "inputs": {
      "text_positive": "portrait photo, Cinematic Hollywood Film, African American girl, 25 years old, walking towards camera, wearing summer dress, scenic automotive background, (sleek modern car:1.2), landscape, freedom, adventure, elegance, casual fashion, vibrant colors, dynamic composition, subject-vehicle balance  cinematic lighting, masterpiece, high quality, high resolution, 4K, HDR, ",
      "text_negative": "Asymmetrical Eyes, Mismatched Eyes, Distorted Eyes, Unaligned Eyes, Blurry Eyes, Overexaggerated Eyes, Inconsistent Lighting on Eyes, Unnatural Eye Color, Floating Eyes, Missing Eyelids, ugly, deformed, noisy, blurry, low contrast, realistic, ugly breasts, tripod, camera, anime, animation, cartoon, 3D, drawing, painting, (censorship, censored, worst quality, low quality, normal quality, lowres, low details, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3) (ugly hands, ugly anatomy, ugly body, ugly face, ugly teeth, ugly arms, ugly legs, deformities:1.3) ugly fingers, bad fingers, (((ugly nipples, bad nipples, deformed nipples))), (((Bad teeth, ugly teeth)))",
      "style": "base",
      "log_prompt": true,
      "style_positive": true,
      "style_negative": true
    },
    "class_type": "SDXLPromptStyler",
    "_meta": {
      "title": "SDXL Prompt Styler"
    }
  },
  "65": {
    "inputs": {
      "ckpt_name": "sdXL_v10VAEFix.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "67": {
    "inputs": {
      "ascore": 6.67,
      "width": 1024,
      "height": 1024,
      "text": "",
      "clip": [
        "65",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXLRefiner",
    "_meta": {
      "title": "CLIPTextEncodeSDXLRefiner"
    }
  },
  "68": {
    "inputs": {
      "ascore": 6,
      "width": 1024,
      "height": 1024,
      "text": "",
      "clip": [
        "65",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXLRefiner",
    "_meta": {
      "title": "CLIPTextEncodeSDXLRefiner"
    }
  },
  "69": {
    "inputs": {
      "vae_name": "sdxl_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "133": {
    "inputs": {
      "width": [
        "183",
        0
      ],
      "height": [
        "183",
        1
      ],
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 4096,
      "target_height": 4096,
      "text_g": [
        "55",
        0
      ],
      "text_l": [
        "55",
        0
      ],
      "clip": [
        "53",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL",
    "_meta": {
      "title": "CLIPTextEncodeSDXL"
    }
  },
  "134": {
    "inputs": {
      "width": [
        "183",
        0
      ],
      "height": [
        "183",
        1
      ],
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 4096,
      "target_height": 4096,
      "text_g": [
        "55",
        1
      ],
      "text_l": [
        "55",
        1
      ],
      "clip": [
        "53",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL",
    "_meta": {
      "title": "CLIPTextEncodeSDXL"
    }
  },
  "149": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "181": {
    "inputs": {
      "strength": 0.5,
      "start_percent": 0,
      "end_percent": 0.65,
      "positive": [
        "133",
        0
      ],
      "negative": [
        "134",
        0
      ],
      "control_net": [
        "22",
        0
      ],
      "image": [
        "28",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "182": {
    "inputs": {
      "strength": 0.4,
      "start_percent": 0,
      "end_percent": 0.65,
      "positive": [
        "181",
        0
      ],
      "negative": [
        "181",
        1
      ],
      "control_net": [
        "29",
        0
      ],
      "image": [
        "33",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "183": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "aspect_ratio": "4:3 landscape 1152x896",
      "swap_dimensions": "Off",
      "upscale_factor1": 1,
      "upscale_factor2": 1,
      "batch_size": 4
    },
    "class_type": "CR Aspect Ratio SDXL",
    "_meta": {
      "title": "CR Aspect Ratio SDXL (Legacy)"
    }
  },
  "192": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 363127728637131,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "start_at_step": 0,
      "end_at_step": 18,
      "return_with_leftover_noise": "enable",
      "model": [
        "53",
        0
      ],
      "positive": [
        "182",
        0
      ],
      "negative": [
        "182",
        1
      ],
      "latent_image": [
        "51",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "193": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": 442614990692167,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "start_at_step": 18,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "65",
        0
      ],
      "positive": [
        "67",
        0
      ],
      "negative": [
        "68",
        0
      ],
      "latent_image": [
        "192",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "194": {
    "inputs": {
      "samples": [
        "193",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "205": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "211": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "221": {
    "inputs": {
      "wildcard": "",
      "Select to add LoRA": "Select the LoRA to add to the text",
      "Select to add Wildcard": "Select the Wildcard to add to the text",
      "model": [
        "53",
        0
      ],
      "clip": [
        "53",
        1
      ],
      "vae": [
        "69",
        0
      ],
      "positive": [
        "133",
        0
      ],
      "negative": [
        "134",
        0
      ],
      "refiner_model": [
        "65",
        0
      ],
      "refiner_clip": [
        "65",
        1
      ],
      "refiner_positive": [
        "67",
        0
      ],
      "refiner_negative": [
        "68",
        0
      ],
      "bbox_detector": [
        "205",
        0
      ],
      "sam_model_opt": [
        "211",
        0
      ]
    },
    "class_type": "ToDetailerPipeSDXL",
    "_meta": {
      "title": "ToDetailerPipeSDXL"
    }
  },
  "223": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "194",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}