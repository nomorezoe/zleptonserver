{
  "2": {
    "inputs": {
      "image": "download.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "5": {
    "inputs": {
      "use_tiled_vae": true,
      "encoder_tile_size": [
        "36",
        0
      ],
      "decoder_tile_size": [
        "36",
        0
      ],
      "encoder_dtype": "auto",
      "SUPIR_VAE": [
        "21",
        1
      ],
      "image": [
        "13",
        0
      ]
    },
    "class_type": "SUPIR_first_stage",
    "_meta": {
      "title": "SUPIR First Stage (Denoiser)"
    }
  },
  "7": {
    "inputs": {
      "seed": 174277455657960,
      "steps": 10,
      "cfg_scale_start": 2,
      "cfg_scale_end": 1.5,
      "EDM_s_churn": 5,
      "s_noise": 1.002,
      "DPMPP_eta": 1,
      "control_scale_start": 1,
      "control_scale_end": 0.9,
      "restore_cfg": 1,
      "keep_model_loaded": false,
      "sampler": "RestoreDPMPP2MSampler",
      "sampler_tile_size": [
        "36",
        0
      ],
      "sampler_tile_stride": [
        "37",
        0
      ],
      "SUPIR_model": [
        "21",
        0
      ],
      "latents": [
        "11",
        0
      ],
      "positive": [
        "9",
        0
      ],
      "negative": [
        "9",
        1
      ]
    },
    "class_type": "SUPIR_sample",
    "_meta": {
      "title": "SUPIR Sampler"
    }
  },
  "9": {
    "inputs": {
      "positive_prompt": "high quality, detailed, photograph",
      "negative_prompt": "bad quality, blurry, messy",
      "SUPIR_model": [
        "21",
        0
      ],
      "latents": [
        "5",
        2
      ]
    },
    "class_type": "SUPIR_conditioner",
    "_meta": {
      "title": "SUPIR Conditioner"
    }
  },
  "10": {
    "inputs": {
      "use_tiled_vae": true,
      "decoder_tile_size": [
        "36",
        0
      ],
      "SUPIR_VAE": [
        "21",
        1
      ],
      "latents": [
        "7",
        0
      ]
    },
    "class_type": "SUPIR_decode",
    "_meta": {
      "title": "SUPIR Decode"
    }
  },
  "11": {
    "inputs": {
      "use_tiled_vae": true,
      "encoder_tile_size": [
        "36",
        0
      ],
      "encoder_dtype": "auto",
      "SUPIR_VAE": [
        "5",
        0
      ],
      "image": [
        "5",
        1
      ]
    },
    "class_type": "SUPIR_encode",
    "_meta": {
      "title": "SUPIR Encode"
    }
  },
  "13": {
    "inputs": {
      "width": [
        "39",
        0
      ],
      "height": [
        "39",
        1
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 32,
      "image": [
        "2",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "21": {
    "inputs": {
      "supir_model": "SUPIR-v0F.ckpt",
      "fp8_unet": false,
      "diffusion_dtype": "auto",
      "high_vram": false,
      "model": [
        "22",
        0
      ],
      "clip": [
        "22",
        1
      ],
      "vae": [
        "22",
        2
      ]
    },
    "class_type": "SUPIR_model_loader_v2",
    "_meta": {
      "title": "SUPIR Model Loader (v2)"
    }
  },
  "22": {
    "inputs": {
      "ckpt_name": "dreamshaperXL_v21TurboDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "25": {
    "inputs": {
      "upscale_by": 2,
      "seed": 720738182146116,
      "steps": 25,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "sgm_uniform",
      "denoise": 0.2,
      "mode_type": "None",
      "tile_width": 1024,
      "tile_height": 1024,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": "enable",
      "tiled_decode": false,
      "image": [
        "10",
        0
      ],
      "model": [
        "22",
        0
      ],
      "positive": [
        "27",
        0
      ],
      "negative": [
        "31",
        0
      ],
      "vae": [
        "22",
        2
      ],
      "upscale_model": [
        "26",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "26": {
    "inputs": {
      "model_name": "4x_foolhardy_Remacri.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "27": {
    "inputs": {
      "text": "best quality,8K",
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "31": {
    "inputs": {
      "text": "(bad anatomy:1.4), (bad proportions:1.3), (deformed:1.3), (ugly:1.2), (mutated:1.2), (extra limbs:1.4), (missing limbs:1.3), (disconnected limbs:1.3), (mutation:1.2), (malformed:1.2), (disfigured:1.3), (cloned face:1.3), (gross proportions:1.3), (mutated hands:1.4), (poorly drawn hands:1.4), (extra hands:1.4), (fused hands:1.3), (missing hands:1.3), (disconnected hands:1.3), (extra fingers:1.4), (missing fingers:1.3), (too many fingers:1.4), (long fingers:1.3), (mutated fingers:1.3), (interlocked fingers:1.2), (extra arms:1.3), (missing arms:1.3), (disconnected arms:1.3), (extra legs:1.3), (missing legs:1.3), (disconnected legs:1.3), (fusion:1.2), (poorly drawn face:1.4), (bad face:1.3), (fused face:1.3), (cloned face:1.3), (weird face:1.2), (double face:1.3), (missing face:1.4), (floating face:1.3), (disconnected face:1.3), (malformed face:1.3), (asymmetrical face:1.2), (cropped face:1.2), (out of frame face:1.2), (extra eyes:1.4), (missing eyes:1.3), (floating eyes:1.3), (disconnected eyes:1.3), (crossed eyes:1.2), (misaligned eyes:1.2), (asymmetrical eyes:1.2), (weird eyes:1.2), (extra mouth:1.3), (missing mouth:1.3), (floating mouth:1.3), (disconnected mouth:1.3), (weird mouth:1.2), (bad mouth:1.2), (extra nose:1.3), (missing nose:1.3), (floating nose:1.3), (disconnected nose:1.3), (weird nose:1.2), (bad nose:1.2), (extra ears:1.3), (missing ears:1.3), (floating ears:1.3), (disconnected ears:1.3), (weird ears:1.2), (bad ears:1.2), (extra head:1.4), (missing head:1.4), (floating head:1.3), (disconnected head:1.4), (weird head:1.2), (bad head:1.2), (extra feet:1.3), (missing feet:1.3), (floating feet:1.3), (disconnected feet:1.3), (weird feet:1.2), (bad feet:1.2), (extra animal ears:1.2), (missing animal ears:1.2), (floating animal ears:1.2), (disconnected animal ears:1.2), (Asian:1.4), (Asian woman:1.4), (Asian girl:1.4), (East Asian:1.4), (Southeast Asian:1.4), (Chinese:1.4), (Japanese:1.4), (Korean:1.4), (Vietnamese:1.4), (Filipina:1.4), (Thai:1.4), (Mongolian:1.4), (Asian features:1.4), (almond-shaped eyes:1.4), (black hair:1.4), (straight black hair:1.4), (dark hair:1.4), (pale skin:1.4), (yellow skin tone:1.4), (slanted eyes:1.4), (epicanthic fold:1.4), (Asian clothing:1.4), (kimono:1.4), (hanbok:1.4), (cheongsam:1.4), (Asian makeup:1.4), (Asian accessories:1.4)",
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "33": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "40",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "36": {
    "inputs": {
      "value": 1024
    },
    "class_type": "ImpactInt",
    "_meta": {
      "title": "Tile Size"
    }
  },
  "37": {
    "inputs": {
      "value": 512
    },
    "class_type": "ImpactInt",
    "_meta": {
      "title": "Tile Stride"
    }
  },
  "39": {
    "inputs": {
      "image": [
        "2",
        0
      ]
    },
    "class_type": "CM_NearestSDXLResolution",
    "_meta": {
      "title": "NearestSDXLResolution"
    }
  },
  "40": {
    "inputs": {
      "guide_size": 512,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 1049761693162276,
      "steps": 20,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "sgm_uniform",
      "denoise": 0.5,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.8,
      "bbox_dilation": 50,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 20,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "image": [
        "25",
        0
      ],
      "model": [
        "22",
        0
      ],
      "clip": [
        "22",
        1
      ],
      "vae": [
        "22",
        2
      ],
      "positive": [
        "27",
        0
      ],
      "negative": [
        "31",
        0
      ],
      "bbox_detector": [
        "43",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "43": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  }
}